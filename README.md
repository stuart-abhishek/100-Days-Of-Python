---

ğŸ 100 Days of Python â€” by Stuart Abhishek

> â€œSmall consistent steps create giant success.â€ â€” Stuart Abhishek




---

ğŸŒ About This Repository

Welcome to my 100 Days of Python challenge!

This repository documents my 100-day journey to master Python â€” one project every day, combining creativity, logic, and real-world problem-solving.
Each project is designed with clean structure, interactive design, and modern programming concepts that reflect the skills of a future Computer Science Engineer at â†’ MIT â†’ Stanford.


---

ğŸ¯ My Vision

ğŸ”¥ Master Python â€” from fundamentals to advanced algorithms.

ğŸ’¡ Think like an engineer, design like an artist, and build like a scientist.

ğŸš€ Develop projects that prove consistency, logic, and innovation.

ğŸ“ Achieve admission into top universities â€” MIT, Stanford â€” through skills and passion.



---

ğŸ§© Progress Tracker

Day	Project	Description	Status

1 	Hello World	My first Python program â€” start of my journey	âœ…
2	 AI Quote Generator	Personalized motivational quote generator	âœ…
3	 Smart Math Quiz	Adaptive arithmetic quiz with scoring & logic	âœ…
4 	Secure Password Engineer	Cryptographically secure password generator + analyzer	âœ…
5 Natural language smart calculator âœ…
6 Smart Data Analyzer âœ…
7 Predictive Insight Engine âœ…
8 From Scratch Naive Bayes Text Classifier âœ…
9 Clustering Insight Engine âœ…


---

ğŸ“˜ Project Details


---

ğŸ§  Day 1 â€” Hello World ğŸ‘‹

ğŸ”¹ Project Title

Hello World Program â€” My first step into the world of programming.

ğŸ”¹ Description

A simple Python script that prints a motivational message.
This marks the beginning of my 100-day journey â€” the foundation of everything that follows.

ğŸ”¹ Code

# Day 1 â€“ Hello World Program
# Author: Stuart Abhishek

print("Hello, World! This is Day 1 of my 100 Days of Python challenge.")

ğŸ”¹ Example Output

Hello, World! This is Day 1 of my 100 Days of Python challenge.

ğŸ”¹ What I Learned

Basic Python syntax

Printing output to the console

My first taste of programming discipline ğŸ’ª



---

ğŸ§  Day 2 â€” AI-Style Quote Generator ğŸ¤–

ğŸ”¹ Project Title

AI Quote Generator â€” A personalized AI-like motivational quote system.

ğŸ”¹ Description

This Python script interacts with the user to create motivational quotes based on their name and goal.
It uses randomness and time-based logic to create human-like responses â€” blending creativity with computation.

ğŸ”¹ Code

# Day 2 â€“ AI-Style Quote Generator
# Author: Stuart Abhishek

import random, datetime

print("ğŸ¤– Welcome to the AI Quote Generator!")
print("Let's create a personalized quote to inspire you today.\n")

name = input("What is your name? ")
goal = input("Whatâ€™s one goal youâ€™re working on right now? ")

quotes = [
  f"{name}, remember â€” every expert was once a beginner. Keep pushing toward {goal}!",
  f"Success doesnâ€™t come from what you do occasionally, {name}, it comes from what you do consistently for {goal}.",
  f"{name}, when you feel like quitting, think about why you started {goal}.",
  f"The future belongs to those like {name} who never stop learning while chasing {goal}.",
  f"{name}, small steps every day towards {goal} will lead to massive results."
]

quote = random.choice(quotes)
hour = datetime.datetime.now().hour
greeting = "Good morning" if hour < 12 else "Good afternoon" if hour < 18 else "Good evening"

print("\n" + "="*60)
print(f"{greeting}, {name}! ğŸŒŸ")
print("Hereâ€™s your motivational message:")
print(f"ğŸ’¬  {quote}")
print("="*60)
print("~ Program created by Stuart Abhishek (Day 2 of 100 Days of Python) ~")

ğŸ”¹ Example Output

ğŸ¤– Welcome to the AI Quote Generator!
Let's create a personalized quote to inspire you today.

What is your name? Stuart
Whatâ€™s one goal youâ€™re working on right now? Python mastery

============================================================
Good evening, Stuart! ğŸŒŸ
Hereâ€™s your motivational message:
ğŸ’¬  Stuart, when you feel like quitting, think about why you started Python mastery.
============================================================
~ Program created by Stuart Abhishek (Day 2 of 100 Days of Python) ~

ğŸ”¹ Concepts Used

Variables & Input

Randomization

datetime module

String formatting

Conditional statements


ğŸ”¹ What I Learned

How to make interactive programs

Personalization through logic

Creating â€œhuman-feelingâ€ code ğŸ¤–



---

ğŸ§  Day 3 â€” Smart Math Quiz ğŸ¯

ğŸ”¹ Project Title

Smart Math Quiz â€” Adaptive arithmetic quiz with scoring & difficulty levels.

ğŸ”¹ Description

This quiz challenges users with math problems that automatically increase in difficulty as you score higher.
It rewards accuracy, penalizes errors, and gives a professional performance summary â€” simulating a smart learning system.

ğŸ”¹ Code

# Day 3 â€“ Smart Math Quiz with Scoring System
# Author: Stuart Abhishek

import random, time

def generate_question(level):
  if level == 1:
    a, b = random.randint(1, 10), random.randint(1, 10)
    op = random.choice(['+', '-'])
  elif level == 2:
    a, b = random.randint(10, 50), random.randint(1, 20)
    op = random.choice(['+', '-', '*'])
  else:
    a, b = random.randint(20, 100), random.randint(1, 25)
    op = random.choice(['+', '-', '*', '//'])
  question = f"{a} {op} {b}"
  return question, eval(question)

def math_quiz():
  print("ğŸ§® Welcome to the Smart Math Quiz!")
  print("Answer as many questions as you can. Type 'quit' to stop.\n")

  level = 1; score = 0; count = 0; start = time.time()
  while True:
    count += 1
    q, ans = generate_question(level)
    user = input(f"Q{count}: {q} = ")
    if user.lower() == "quit": break
    try:
      if int(user) == ans:
        score += 10
        print("âœ… Correct!")
        if score % 50 == 0:
          level = min(level + 1, 3)
          print("ğŸš€ Level Up! Difficulty increased.")
      else:
        score -= 5
        print(f"âŒ Wrong! Correct answer was {ans}.")
    except ValueError:
      print("âš ï¸ Enter a number or 'quit'.")
    print(f"Current Score: {score}\n")

  t = round(time.time() - start, 2)
  print("="*55)
  print("ğŸ Quiz Summary")
  print(f"Questions: {count - 1} | Final Score: {score} | Time: {t}s")
  if score >= 100: print("ğŸŒŸ Brilliant work!")
  elif score >= 50: print("ğŸ’ª Great job!")
  else: print("ğŸ“˜ Keep practicing!")
  print("="*55)
  print("~ Program created by Stuart Abhishek (Day 3 of 100 Days of Python) ~")

if __name__ == "__main__":
  math_quiz()

ğŸ”¹ Example Output

Q1: 3 + 4 = 7
âœ… Correct!
Current Score: 10

Q2: 12 - 8 = 4
âœ… Correct!
Current Score: 20

Q3: 6 * 5 = 31
âŒ Wrong! Correct answer was 30.
Current Score: 15

ğŸ”¹ Concepts Used

Functions & Modular Design

Loops & Conditionals

Randomization & Adaptive Logic

Scoring Systems

Time Measurement


ğŸ”¹ What I Learned

Structured function design

Adaptive algorithms

Logic building like a real engineer âš™ï¸



---

ğŸ§  Day 4 â€” Secure Password Engineer ğŸ”

ğŸ”¹ Project Title

Secure Password Engineer â€” Cryptographically secure password generator + strength analyzer.

ğŸ”¹ Description

This professional-grade program creates uncrackable passwords and analyzes their strength using:

Entropy calculations

Pattern detection

Sequential run identification

Ambiguity checks

Comprehensive 0â€“100 scoring system


It uses the secrets module (cryptographically secure RNG) and outputs suggestions for improvement â€” just like a mini cybersecurity assistant.

ğŸ”¹ Code Highlights

secrets module for secure randomness

math.log2() for entropy estimation

Regular expressions for pattern detection

Logging system using pathlib

Modular functions and clean CLI


ğŸ”¹ Example Interaction

ğŸ” Secure Password Engineer â€” Day 4
1) Generate a strong password
2) Analyze an existing password
3) Generate & analyze (recommended)
q) Quit
Choose an option: 3
Desired length (recommend 16â€“24): 18
Include lowercase? [Y/n]:
Include uppercase? [Y/n]:
Include digits? [Y/n]:
Include symbols? [Y/n]:
Avoid ambiguous characters? [Y/n]:

Generated password:
7uG}xVbR%pZt_fH3q*

Score: 93/100 | Grade: Very Strong
Length: 18 | Entropy: 113.61 bits
Longest sequential run: 1
Repeated runs: False | Common pattern: False

Suggestions:
â€¢ Great length â€” keep 16+ for stronger security.
â€¢ Excellent character diversity â€” 4 categories used.

ğŸ”¹ Concepts Used

Cryptography & Secure Randomness

Entropy and Information Theory

Pattern Recognition

Data Validation

File Logging and Modular Programming


ğŸ”¹ What I Learned

Difference between random and secrets

How to measure password entropy mathematically

Writing security-conscious, user-friendly code

Designing an AI-style analytical program


---

## ğŸ§  Day 5 â€” Natural-Language Smart Calculator ğŸ¤–

### ğŸ”¹ Project Title
**Smart Calculator** â€” Understands human language to perform arithmetic.

### ğŸ”¹ Project Description
A Python program that interprets natural-language expressions like  
â€œadd 12 and 45â€, â€œsubtract 10 from 50â€, â€œsquare root of 81â€,  
and computes accurate results.  
It mimics early natural-language interfaces â€” showing algorithmic reasoning and text processing skills.

### ğŸ”¹ Concepts Used
- Regular Expressions (`re`) for text extraction  
- Conditional Logic for intent detection  
- Mathematical operations (`math` module)  
- Exception handling  
- Clean modular programming  

### ğŸ”¹ Example Output

ğŸ§® Welcome to the Natural-Language Smart Calculator! ğŸ‘‰ Enter expression: add 24 and 65 âœ… Result: 89.0

ğŸ‘‰ Enter expression: subtract 10 from 42 âœ… Result: 32.0

ğŸ‘‰ Enter expression: square root of 81 âœ… Result: 9.0

ğŸ‘‰ Enter expression: cube of 3 âœ… Result: 27.0

### ğŸ”¹ What I Learned
- Translating language into computation  
- Regex pattern matching and token parsing  
- Handling ambiguous input gracefully  
- Thinking algorithmically like a language-model designer  

### ğŸ”¹ Future Improvements
- Integrate `nltk` or `spaCy` for deeper natural-language parsing  
- Add unit conversion and scientific-mode operations

---

## ğŸ§  Day 6 â€” Smart Data Analyzer ğŸ“Š

### ğŸ”¹ Project Title
**Smart Data Analyzer** â€” automatic statistical and correlation analysis of CSV datasets.

### ğŸ”¹ Project Description
This Python engine loads any CSV file and instantly produces summary statistics, detects strong correlations, and provides simple â€œinsights.â€  
It demonstrates data-science fundamentals, algorithmic thinking, and data-driven storytelling.

### ğŸ”¹ Concepts Used
- File I/O & CSV parsing (`csv.DictReader`)
- Statistics & probability (`statistics`, `math`)
- Correlation coefficient computation
- Data visualization with `matplotlib`
- Algorithmic automation & reporting

### ğŸ”¹ Example Output

ğŸ“Š Smart Data Analyzer â€” Day 6 Enter CSV file path (e.g., data.csv): students.csv

ğŸ“ˆ Summary Statistics â€¢ Math: mean=78.4, median=80.0, stdev=10.2, n=50 â€¢ Science: mean=76.1, median=75.0, stdev=9.5, n=50 â€¢ English: mean=81.6, median=82.0, stdev=8.9, n=50

ğŸ¤ Significant Correlations (|r| â‰¥ 0.5) Math â†” Science: r = 0.91 (direct correlation) English â†” Math: r = 0.73 (direct correlation)

âœ¨ Insights: Strongest link: Math and Science (0.91). Consider exploring cause-effect relationship. Report complete âœ…

### ğŸ”¹ What I Learned
- Reading structured data programmatically  
- Statistical reasoning (mean, median, stdev, correlation)  
- Automating analysis workflows like real data scientists  
- Presenting information visually and narratively  

### ğŸ”¹ Future Improvements
- Integrate `pandas` for larger datasets  
- Export summary reports as PDF  
- Apply linear regression to predict relationships  
- Build a web dashboard using `Streamlit`

---
  
## ğŸ§  Day 7 â€” Predictive Insight Engine ğŸ“ˆ

### ğŸ”¹ Project Title
**Predictive Insight Engine** â€” Univariate Linear Regression with Cross-Validation, Outlier Handling, Plots, and a Model Card.

### ğŸ”¹ Project Description
A disciplined mini-ML pipeline:
- Loads a CSV, selects a numeric feature (X) and target (Y)
- Optional z-score outlier removal
- Standardizes features/targets
- Trains linear regression via gradient descent with early stopping
- Reports **RÂ², MAE, RMSE** and performs **5-fold cross-validation**
- Shows **fitted line** and **residual diagnostics** plots
- Exports a **JSON model card** (coefficients, scalers, CV metrics, metadata)

### ğŸ”¹ Concepts Used
- Data hygiene (z-scores), standardization
- Gradient descent & early stopping
- Generalization via cross-validation
- Multiple evaluation metrics (RÂ², MAE, RMSE)
- Residual analysis and visualization
- Reproducibility (JSON model card)

### ğŸ”¹ Example Session

ğŸ“ˆ Predictive Insight Engine â€” Day 7 Enter CSV path (e.g., data.csv): students.csv Choose FEATURE (X):

1. StudyHours


2. SleepHours


3. MathScore Select number: 1 Choose TARGET (Y):


4. MathScore


5. ScienceScore Select number: 1 Remove outliers with z-score > 3? [Y/n]: Y Outlier filter: 52 â†’ 50 usable pairs.



ğŸ” 5-fold Cross-Validation R2_mean: 0.8123 R2_std: 0.0431 MAE_mean: 3.215 RMSE_mean: 4.097

âœ… Fitted on full data RÂ²: 0.8467 | MAE: 2.98 | RMSE: 3.82

Show fitted-line plot? [Y/n]: Y Show residuals plot? [Y/n]: Y Save model card JSON? [Y/n]: Y ğŸ“ Model card saved to: Day-07/model_card_StudyHours_to_MathScore.json

### ğŸ”¹ What I Learned
- How to build a small but **serious** ML workflow from scratch  
- Why **cross-validation** matters for generalization  
- Reading models beyond a single score using residuals  
- The importance of **reproducibility** through a model card

### ğŸ”¹ Future Improvements
- Multi-feature regression (normal equations)
- Polynomial basis expansion with regularization
- Confidence intervals and prediction intervals
- Export plots + report as a single HTML/PDF


---

## ğŸ§  Day 8 â€” From-Scratch Naive Bayes Text Classifier ğŸ“¨

### ğŸ”¹ Project Title
**Naive Bayes Text Classifier** â€” pure-Python NLP classifier with CV, explainability, and a model card.

### ğŸ”¹ Project Description
A full, explainable NLP pipeline implemented **from scratch**:
- Tokenizes text (stopword filtering)
- Trains a **Multinomial Naive Bayes** with **Laplace smoothing**
- Performs **5-fold cross-validation** (macro precision/recall/F1, accuracy)
- Prints a **confusion matrix**
- Shows **most-informative tokens** via class log-odds
- Exports a **JSON model card** (priors, vocab size, CV metrics, metadata)
- Includes an **interactive demo** for live classification

**Input format:** CSV with columns: `text`, `label`.

### ğŸ”¹ Concepts Used
- Probabilistic modeling (Naive Bayes)
- Tokenization, stopwords, <UNK> handling
- Cross-validation for generalization
- Macro-averaged **precision/recall/F1**
- Explainability (log-odds indicative tokens)
- Reproducibility (JSON model card)

### ğŸ”¹ Example Session

ğŸ§  Day 8 â€” Naive Bayes Text Classifier (From Scratch) Enter CSV path (must include columns 'text','label'): sms_spam.csv Laplace smoothing alpha [default 1.0]: Keep numeric tokens? [y/N]: y

ğŸ” 5-fold Cross-Validation (macro-averaged): accuracy: 0.962 precision_macro: 0.955 recall_macro: 0.948 f1_macro: 0.951

âœ… Fit on full data (reference metrics): accuracy: 0.971 precision_macro: 0.966 recall_macro: 0.959 f1_macro: 0.962

Confusion Matrix (rows=true, cols=pred): ham   spam ham    480     12 spam      5     73

ğŸ’¡ Most-informative tokens (log-odds): ham vs spam: meeting(2.31), home(2.07), okay(1.98), call(1.72), ... spam vs ham: free(3.45), prize(3.23), claim(3.10), txt(2.88), win(2.76), ... ğŸ“ Model card saved to: Day-08/model_card_naive_bayes.json text> win a free prize now! Predicted: spam  |  Probabilities: {'ham': 0.013, 'spam': 0.987}

### ğŸ”¹ What I Learned
- Implementing a classic ML algorithm from first principles
- Measuring generalization with CV (not just train accuracy)
- Reading models via **most-informative features**
- Building explainable, documented ML pipelines

### ğŸ”¹ Future Improvements
- Add TF-IDF weighting
- Character-level n-grams for robustness
- ROC-AUC, PR-AUC plots
- Save/load trained model for reuse


---

## ğŸ§  Day 9 â€” Clustering Insight Engine ğŸŒ

### ğŸ”¹ Project Title
**Clustering Insight Engine** â€” K-Means + PCA implemented from scratch with visualization and a model card.

### ğŸ”¹ Project Description
An unsupervised-learning engine that groups data into clusters, projects them via PCA, and visualizes patterns.  
It measures convergence, inertia, and exports a reproducible JSON summary.  
Demonstrates linear algebra, optimization, and data visualization fundamentals.

### ğŸ”¹ Concepts Used
- K-Means clustering (centroid update, inertia)
- PCA (eigenvectors via power iteration)
- Z-score normalization
- Algorithm convergence & tolerance
- Data visualization (`matplotlib`)
- Reproducibility via model card

### ğŸ”¹ Example Output

ğŸŒ Day 9 â€” Clustering Insight Engine Enter CSV path: iris_numeric.csv Number of clusters (k): 3

âœ… K-Means finished in 12 iterations. Inertia: 48.72 Cluster sizes: [52, 50, 48] ğŸ“ Saved Day-09/model_card_kmeans.json

*(2-D scatter plot of clusters displayed)*

### ğŸ”¹ What I Learned
- Implementing iterative optimization algorithms (K-Means)
- Reducing high-dimensional data with PCA
- Visualizing and interpreting unsupervised results
- Writing clear, reusable scientific code

### ğŸ”¹ Future Improvements
- Add **Elbow method** for automatic k selection  
- Implement **Silhouette score**  
- Extend PCA to N components  
- Build a simple GUI for cluster exploration


---


ğŸŒŸ The Journey Ahead


Each project will advance in difficulty and creativity â€” reflecting both engineering skill and problem-solving ability that top universities like MIT, Stanford, and Harvard value deeply.


---

âœï¸ Author

ğŸ‘¨â€ğŸ’» Stuart Abhishek
16-year-old aspiring Computer Science Engineer
Dream Path:â†’ MIT / Stanford

> â€œDiscipline beats talent. Consistency builds brilliance.â€




---

ğŸªª License

This repository is licensed under the MIT License â€” free to learn, share, and contribute.


---

ğŸ’« Closing Note

> Every single day of this challenge represents my commitment to become a world-class programmer.
Through logic, creativity, and consistent hard work â€” Iâ€™ll reach the top, one line of code at a time.




---